{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for CS6378 Project\n",
    "## Comparison of real-time filtering technique on FPGA vs. modern CPU\n",
    "### Chris Tsongas cst130030@utdallas.edu\n",
    "### Summary\n",
    "The modules below can be run in sequential order to see the FPGA setup and running processes. The USE_FPGA parameter allows switching between running Sobel filter on the FPGA or within the Zynq CPU. \n",
    "\n",
    "To start, download the base overlay and instantiate the HDMI input and output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%microblaze/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%pybind11/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pynq.overlays.base import BaseOverlay\n",
    "from pynq.lib.video import *\n",
    "import cv2, time, warnings\n",
    "import numpy as np\n",
    "warnings.filterwarnings('ignore')\n",
    "import pynq\n",
    "from pynq import Overlay\n",
    "from pynq import allocate\n",
    "\n",
    "overlay = BaseOverlay('base_w_sobel.bit')\n",
    "\n",
    "sobel = overlay.sobel_0\n",
    "dma = overlay.axi_dma_0\n",
    "\n",
    "hdmi_in = overlay.video.hdmi_in\n",
    "hdmi_out = overlay.video.hdmi_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "\n",
    "Initialize the Memory and Button Interrupt for buffering input video to the FPGA filter, Create the HDMI input and HDMI output streams as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib._GeneratorContextManager at 0xb48360a0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dma_reset():\n",
    "    dma.sendchannel.stop()\n",
    "    dma.recvchannel.stop()\n",
    "    dma.sendchannel.start()\n",
    "    dma.recvchannel.start()\n",
    "dma_reset()\n",
    "\n",
    "def buttonInterrupt():\n",
    "    return False if overlay.buttons[3].read() == 0 else True\n",
    "\n",
    "hdmi_in.configure(PIXEL_GRAY)\n",
    "hdmi_out.configure(hdmi_in.mode)\n",
    "hdmi_in.cacheable_frames = False\n",
    "hdmi_out.cacheable_frames = False\n",
    "hdmi_in.start()\n",
    "hdmi_out.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the shared/FPGA parameters\n",
    "This function will initialize the FPGA Filter buffers and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "KERNEL_SIZE = 3\n",
    "USE_FPGA = True\n",
    "HORIZONTAL = hdmi_in.mode.width\n",
    "VERTICAL = hdmi_in.mode.height\n",
    "RESOLUTION = (VERTICAL, HORIZONTAL)\n",
    "# To avoid the need for padding, set input and output to DMA as squares\n",
    "FP_VBLANK = (max(RESOLUTION) - min(RESOLUTION)) // 2\n",
    "BP_VBLANK = FP_VBLANK + min(RESOLUTION)\n",
    "BUFFER_SHAPE = max(RESOLUTION)\n",
    "# Static values used to initialize FPGA Sobel filter\n",
    "FIRST_PIXEL_CMD = 0x10\n",
    "LAST_PIXEL_CMD = 0x18\n",
    "CONTROL_REG = 0x00\n",
    "START_CMD = 0x81\n",
    "\n",
    "input_buffer = allocate(shape=(BUFFER_SHAPE, BUFFER_SHAPE), dtype=np.uint8)\n",
    "output_buffer = allocate(shape=(BUFFER_SHAPE, BUFFER_SHAPE), dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to call to run the Sobel filter on FPGA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sobel():\n",
    "    #reset memory each frame\n",
    "    dma_reset()\n",
    "    # setup memory transfers\n",
    "    dma.sendchannel.transfer(input_buffer)\n",
    "    dma.recvchannel.transfer(output_buffer)\n",
    "    # setup sobel HLS that is in-between memory interfaces\n",
    "    sobel.write(FIRST_PIXEL_CMD, BUFFER_SHAPE)\n",
    "    sobel.write(LAST_PIXEL_CMD, BUFFER_SHAPE)\n",
    "    sobel.write(CONTROL_REG, START_CMD)\n",
    "    # wait for receive and send to finish\n",
    "    dma.sendchannel.wait()\n",
    "    dma.recvchannel.wait()\n",
    "    # output will be captured in output_buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Pass-thru HDMI-IN $\\rightarrow$ HDMI_OUT\n",
    "While this provides for a fast way of passing video data through the pipeline there is no way to access or modify the frames. For that we a loop calling `readframe` and `writeframe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames per second: 58.76213415323896\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "numframes = 1\n",
    "start = time.time()\n",
    "\n",
    "while (buttonInterrupt() == False):\n",
    "    fstime = time.time()\n",
    "    f = hdmi_in.readframe()\n",
    "    cv2.putText(f, \"FPS: \" + str(round(1/(time.time()-fstime),4)),(1,20),0,0.8,(255,255,255),1)\n",
    "    hdmi_out.writeframe(f)\n",
    "    numframes+=1\n",
    "\n",
    "end = time.time()\n",
    "print(\"Frames per second: \" + str(numframes / (end - start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can start adding some filtering into the mix. \n",
    "The for loop will convert input to gray-scale then apply the filter based on parameters above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT SHAPE : (720, 1280)\n",
      "OUTPUT SHAPE : (720, 1280)\n",
      "Frames per second: 12.197324333434295\n"
     ]
    }
   ],
   "source": [
    "result = np.ndarray(shape=RESOLUTION, dtype=np.uint8)\n",
    "\n",
    "start = time.time()\n",
    "numframes = 1\n",
    "#while( numframes < 100 ):\n",
    "while (buttonInterrupt() == False):\n",
    "    fstime = time.time()\n",
    "    ###############################################################\n",
    "    # Read input from HDMI_IN\n",
    "    ###############################################################\n",
    "    inframe = hdmi_in.readframe()\n",
    "    if ( numframes == 1 ):\n",
    "        print(\"INPUT SHAPE : \" + str(inframe.shape))\n",
    "    if ( USE_FPGA ):\n",
    "        # Only apply padding and send to memory when using FPGA hardware\n",
    "        inframe = cv2.copyMakeBorder(inframe, FP_VBLANK, FP_VBLANK, 0, 0, cv2.BORDER_CONSTANT, value=[0,0,0])\n",
    "        input_buffer[:,:] = inframe\n",
    "    \n",
    "    ###############################################################\n",
    "    # Apply kernel\n",
    "    ###############################################################\n",
    "    outframe = hdmi_out.newframe()\n",
    "    # sobel with custom FPGA hardware\n",
    "    if ( USE_FPGA ):\n",
    "        run_sobel()\n",
    "    else:\n",
    "        cv2.Laplacian(inframe, cv2.CV_8U,ksize=KERNEL_SIZE, dst=outframe)\n",
    "    \n",
    "    ###############################################################\n",
    "    # Write output to HDMI_OUT\n",
    "    ###############################################################\n",
    "    \n",
    "    if ( USE_FPGA ):\n",
    "        # Remove the front and back porch of the memory to reformat into HDMI_IN size\n",
    "        outframe = output_buffer[FP_VBLANK:BP_VBLANK, :]\n",
    "    \n",
    "    if ( numframes == 1 ):\n",
    "        print(\"OUTPUT SHAPE : \" + str(outframe.shape))\n",
    "    # Commented out to avoid large FPS penalty\n",
    "    \n",
    "    cv2.putText(outframe, \"FPS: \" + str(round(1/(time.time()-fstime),4)),(1,20),0,0.8,(255,255,255),1)\n",
    "    hdmi_out.writeframe(outframe)\n",
    "    numframes+=1\n",
    "\n",
    "end = time.time()\n",
    "print(\"Frames per second: \" + str(numframes / (end - start)))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning up\n",
    "\n",
    "Finally you must always stop the interfaces when you are done with them. Otherwise bad things can happen when the bitstream is reprogrammed. You can also use the HDMI interfaces in a context manager to ensure that the cleanup is always performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdmi_out.close()\n",
    "hdmi_in.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-running the plain read-write loop now shows 60 FPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numframes = 600\n",
    "start = time.time()\n",
    "\n",
    "for _ in range(numframes):\n",
    "    f = hdmi_in.readframe()\n",
    "    hdmi_out.writeframe(f)\n",
    "    \n",
    "end = time.time()\n",
    "print(\"Frames per second:  \" + str(numframes / (end - start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the expense of much slower OpenCV performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numframes = 10\n",
    "start = time.time()\n",
    "\n",
    "for _ in range(numframes):\n",
    "    inframe = hdmi_in.readframe()\n",
    "    cv2.cvtColor(inframe,cv2.COLOR_BGR2GRAY,dst=grayscale)\n",
    "    # inframe.freebuffer()\n",
    "    cv2.Laplacian(grayscale, cv2.CV_8U, dst=result)\n",
    "\n",
    "    outframe = hdmi_out.newframe()\n",
    "    cv2.cvtColor(result, cv2.COLOR_GRAY2BGR,dst=outframe)\n",
    "    hdmi_out.writeframe(outframe)\n",
    "    \n",
    "end = time.time()\n",
    "print(\"Frames per second:  \" + str(numframes / (end - start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdmi_out.close()\n",
    "hdmi_in.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gray-scale\n",
    "Using the new infrastructure we can delegate the color conversion to the hardware as well as only passing a single grayscale pixel to and from the processor.\n",
    "\n",
    "First reconfigure the pipelines in grayscale mode and tie the two together to make sure everything is working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.download()\n",
    "\n",
    "hdmi_in.configure(PIXEL_GRAY)\n",
    "hdmi_out.configure(hdmi_in.mode)\n",
    "hdmi_in.cacheable_frames = True\n",
    "hdmi_out.cacheable_frames = True\n",
    "hdmi_in.start()\n",
    "hdmi_out.start()\n",
    "\n",
    "hdmi_in.tie(hdmi_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can rewrite the loop without the software colour conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "numframes = 30\n",
    "\n",
    "for _ in range(numframes):\n",
    "    inframe = hdmi_in.readframe()\n",
    "    outframe = hdmi_out.newframe()\n",
    "    cv2.Laplacian(inframe, cv2.CV_8U, dst=outframe)\n",
    "    # inframe.freebuffer()\n",
    "    hdmi_out.writeframe(outframe)\n",
    "    \n",
    "end = time.time()\n",
    "print(\"Frames per second:  \" + str(numframes / (end - start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdmi_out.close()\n",
    "hdmi_in.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other modes\n",
    "\n",
    "There are two other 24 bit modes that are useful for interacting with PIL. The first is regular RGB mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.download()\n",
    "\n",
    "hdmi_in.configure(PIXEL_RGB)\n",
    "hdmi_out.configure(hdmi_in.mode, PIXEL_RGB)\n",
    "\n",
    "hdmi_in.start()\n",
    "hdmi_out.start()\n",
    "\n",
    "hdmi_in.tie(hdmi_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is useful for easily creating and displaying frames with Pillow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image\n",
    "\n",
    "frame = hdmi_in.readframe()\n",
    "image = PIL.Image.fromarray(frame)\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative mode is YCbCr which is useful for some image processing algorithms or exporting JPEG files. Because we are not changing the number of bits per pixel we can update the colorspace of the input dynamically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdmi_in.colorspace = COLOR_IN_YCBCR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's probably worth updating the output colorspace as well to avoid the psychedelic  effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdmi_out.colorspace = COLOR_OUT_YCBCR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use PIL to read in the frame and perform the conversion back for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image\n",
    "\n",
    "frame = hdmi_in.readframe()\n",
    "image = PIL.Image.fromarray(frame, \"YCbCr\")\n",
    "frame.freebuffer()\n",
    "image.convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdmi_out.close()\n",
    "hdmi_in.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "This notebook has only provided an overview of base overlay pipeline. One of the reasons for the changes was to make it easier to add hardware accelerated functions by supporting a wider range of pixel formats without software conversion and separating out the HDMI front end from the video DMA. Explore the code in pynq/lib/video.py for more details."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
